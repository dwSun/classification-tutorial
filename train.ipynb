{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow V2.0 图像识别教程\n",
    "\n",
    "教程参考官方专家高级教程：\n",
    "https://tensorflow.google.cn/tutorials/quickstart/advanced?hl=en\n",
    "\n",
    "这里以 TinyMind 《汉字书法识别》比赛数据为例，展示使用 Tensorflow V2.0 进行图像数据分类模型训练的整个流程。\n",
    "\n",
    "数据地址请参考:\n",
    "https://www.tinymind.cn/competitions/41#property_23\n",
    "\n",
    "或到这里下载：\n",
    "自由练习赛数据下载地址：\n",
    "训练集：链接: https://pan.baidu.com/s/1UxvN7nVpa0cuY1A-0B8gjg 密码: aujd\n",
    "\n",
    "测试集: https://pan.baidu.com/s/1tzMYlrNY4XeMadipLCPzTw 密码: 4y9k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据探索\n",
    "请参考官方的数据说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "\n",
    "竞赛中只有训练集 train 数据有准确的标签，因此这里只使用 train 数据即可，实际应用中，阶段 1、2 的榜单都需要使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据下载\n",
    "\n",
    "下载数据之后进行解压，得到 train 文件夹，里面有 100 个文件夹，每个文件夹名字即是各个汉字的标签。类似的数据集结构经常在分类任务中见到。可以使用下述命令验证一下每个文件夹下面文件的数量，看数据集是否符合竞赛数据描述：\n",
    "```sh\n",
    "for l in $(ls); do echo $l $(ls $l|wc -l); done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集\n",
    "\n",
    "因为这里只使用了 train 集，因此我们需要对已有数据集进行划分，供模型训练的时候做验证使用，也就是 validation 集的构建。\n",
    "> 一般认为，train 用来训练模型，validation 用来对模型进行验证以及超参数（ hyper parameter）调整，test 用来做模型的最终验证，我们所谓模型的性能，一般也是指 test 集上模型的性能指标。但是实际项目中，一般只有 train 集，同时没有可靠的 test 集来验证模型，因此一般将 train 集划分出一部分作为 validation，同时将 validation 上的模型性能作为最终模型性能指标。\n",
    "\n",
    "> 一般情况下，我们不严格区分 validation 和 test。\n",
    "\n",
    "这里将每个文件夹下面随机50个文件拿出来做 validation。\n",
    "\n",
    "```sh\n",
    "export train=train\n",
    "export val=validation\n",
    "\n",
    "for d in $(ls $train); do\n",
    "    mkdir -p $val/$d/\n",
    "    for f in $(ls train/$d | shuf | head -n 50 ); do\n",
    "        mv $train/$d/$f $val/$d/;\n",
    "    done;\n",
    "done\n",
    "```\n",
    "\n",
    "> 需要注意，这里的 validation 只间接通过超参数的调整参与了模型训练。因此有一定的数据浪费。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练代码-数据部分\n",
    "首先导入 TF 看一下版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型的时候，模型内部全部都是数字，没有任何可读性，而且这些数字也需要人为给予一些实际的意义，这里将 100 个汉字作为模型输出数字的文字表述。\n",
    "\n",
    "需要注意的是，因为模型训练往往是一个循环往复的过程，因此一个稳定的文字标签是很有必要的，这里利用相关 python 代码在首次运行的时候生成了一个标签文件，后续检测到这个标签文件，则直接调用即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"labels.txt\"):\n",
    "    with open(\"labels.txt\") as inf:\n",
    "        classes = [l.strip() for l in inf]\n",
    "else:\n",
    "    classes = os.listdir(\"worddata/train/\")\n",
    "    with open(\"labels.txt\", \"w\") as of:\n",
    "        of.write(\"\\r\\n\".join(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比于 TF V1.x，V2.x 中一个比较大的变化就是数据集读取和处理的工具更加简单，（虽然效率其实低了一些，但是考虑数据读取在一定的优化下，很少成为模型训练的瓶颈，这一点性能损失带来巨大的便利性，还是值得的）。\n",
    "\n",
    "TF V2.x中提供了直接从目录中读取数据并进行训练的 API 这里使用的API如下。\n",
    "\n",
    "这里使用了两个数据集，分别代表 train、validation。\n",
    "\n",
    "需要注意的是，由于 数据中，使用的图像数据集，其数值在（0， 255）之间，不适合直接输入模型进行训练，因此这里使用 rescale 对数据进行缩放。同时，train 数据集做了一定的数据预处理（旋转、明暗度），用于进行数据增广，而 validation则不需要做类似的变换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0, rotation_range=15, brightness_range=(0.5, 1.0)\n",
    ")\n",
    "img_gen_val = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从 API 的名称和参数可以看出，这个 API 并不直接从目录中读取数据，我们实际使用的时候，要使用这个 API 的一个封装。\n",
    "\n",
    "在这个封装中，我们指定了图像最终的大小（target_size），颜色模式（color_mode），批量大小（batch_size），同时还有一个非常重要的标签（classes）。\n",
    "\n",
    "需要注意的是，这里的 color_mode 使用的是灰度模式，读取出来的数据只有一个颜色通道，因为书法的汉字全部是水墨，无所谓颜色。而 classes的使用，保证每次模型训练都使用统一的标签，如果不指定，那么这个 API 会按照一个内置的规则对标签进行编号，这个编号在不同的系统平台之间可能是不一致的。\n",
    "\n",
    "这里还需要注意一点的是，train 集我们对数据进行了随机打乱 (shuffle)， 而 validation 则没有。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "img_train = img_gen_train.flow_from_directory(\n",
    "    \"worddata/train/\",\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"grayscale\",\n",
    "    classes=classes,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "img_val = img_gen_train.flow_from_directory(\n",
    "    \"worddata/validation/\",\n",
    "    target_size=(128, 128),\n",
    "    color_mode=\"grayscale\",\n",
    "    classes=classes,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里，这两个数据集就可以使用了，正式模型训练之前，我们可以先来看看这个数据集是怎么读取数据的，读取出来的数据又是设么样子的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 128, 128, 1), (32, 100))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, labels = next(img_train)\n",
    "# 因为是 generator 所以可以用next来读取\n",
    "imgs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到数据是（batch, width, height, channel）, 因为这里是灰度图像，因此 channel 是 1。\n",
    "\n",
    "> 需要注意，pyTorch、mxnet使用的数据 layout 与Tensorflow 不同，因此数据也有一些不同的处理方式。\n",
    "\n",
    "把图片打印出来看看，看看数据和标签之间是否匹配\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'从'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(imgs[0, :, :, 0], cmap=\"gray\")\n",
    "classes[np.argsort(labels[0, :])[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练代码-模型构建\n",
    "\n",
    "TF V2.x 中使用动态图来构建模型，同时由于使用了 keras的 API，因此模型构建比较简单了。这里演示的是使用 class的方式构建模型，对于简单模型，还可以直接使用 Sequential 进行构建。\n",
    "\n",
    "这里的复杂模型也是用 Sequential 的简单模型进行的叠加。\n",
    "\n",
    "> 这里构建的是VGG模型，关于VGG模型的更多细节请参考 1409.1556。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 模型有两个主要部分，特征提取层和分类器\n",
    "\n",
    "        # 这里是特征提取层\n",
    "        self.feature = tf.keras.models.Sequential()\n",
    "        self.feature.add(self.conv(64))\n",
    "        self.feature.add(self.conv(64, add_pooling=True))\n",
    "\n",
    "        self.feature.add(self.conv(128))\n",
    "        self.feature.add(self.conv(128, add_pooling=True))\n",
    "\n",
    "        self.feature.add(self.conv(256))\n",
    "        self.feature.add(self.conv(256))\n",
    "        self.feature.add(self.conv(256, add_pooling=True))\n",
    "\n",
    "        self.feature.add(self.conv(512))\n",
    "        self.feature.add(self.conv(512))\n",
    "        self.feature.add(self.conv(512, add_pooling=True))\n",
    "\n",
    "        self.feature.add(self.conv(512))\n",
    "        self.feature.add(self.conv(512))\n",
    "        self.feature.add(self.conv(512, add_pooling=True))\n",
    "\n",
    "        self.feature.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "        self.feature.add(tf.keras.layers.Dense(4096))\n",
    "        self.feature.add(tf.keras.layers.BatchNormalization())\n",
    "        self.feature.add(tf.keras.layers.Dense(4096))\n",
    "        self.feature.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        self.feature.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "        # 这个简单的机构是分类器\n",
    "        # 这里我们将 softmax的操作直接加入了模型结构中。\n",
    "        # 而很多框架的 model zoo 中的模型将 softmax\n",
    "        # 的操作放在模型外执行，可以大大提高模型的灵活性，\n",
    "        # 方便对模型的最终输出做一些其他处理。\n",
    "        self.pred = tf.keras.models.Sequential(\n",
    "            [tf.keras.layers.Dense(100, activation=None), tf.keras.layers.Softmax(),]\n",
    "        )\n",
    "\n",
    "    def conv(self, filters, add_pooling=False):\n",
    "        # 模型大量使用重复模块构建，\n",
    "        # 这里将重复模块提取出来，简化模型构建过程\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(filters, 3, padding=\"same\", activation=\"relu\"),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "            ]\n",
    "        )\n",
    "        if add_pooling:\n",
    "            model.add(\n",
    "                tf.keras.layers.MaxPool2D(\n",
    "                    pool_size=(2, 2), strides=None, padding=\"same\"\n",
    "                )\n",
    "            )\n",
    "        return model\n",
    "\n",
    "    def call(self, x):\n",
    "        # call 用来定义模型各个结构之间的运算关系\n",
    "\n",
    "        x = self.feature(x)\n",
    "        return self.pred(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，上述模型定义中，仅仅关注当前模块的参数即可，模块的输入及输出的关系由框架自动推算得到，节省了很多精力。\n",
    "\n",
    "> 这跟 TF 1.x 有很大不同，也跟 pyTorch有很大不同。mxnet 的 gluon api 跟这里的操作是类似的。\n",
    "\n",
    "实例化一个模型看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      multiple                  33645760  \n",
      "_________________________________________________________________\n",
      "sequential_14 (Sequential)   multiple                  409700    \n",
      "=================================================================\n",
      "Total params: 34,055,460\n",
      "Trainable params: 34,030,628\n",
      "Non-trainable params: 24,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "\n",
    "model.build(input_shape=(None, 128, 128, 1))\n",
    "# 这里的build，是因为模型构建的时候，并没有指定输入数据的尺寸，\n",
    "# 因此要查看模型的一些数据，需要告知模型的输入数据尺寸，框架据\n",
    "# 此推断模型内部各模块参数。\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build 和 summary 仅仅用来查看模型数据，对于模型训练不是必须的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练代码-训练相关部分\n",
    "要训练模型，我们还需要定义损失，优化器等，同时为了方便训练过程对模型进行验证，我们还需要定义一些性能指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam() # 优化器有些参数可以设置\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF V1.x 中，模型的训练是需要启动一个 Session 的，而在 TF V2.x中，这个 Session的操作被隐藏了起来，取而代之的是 tf.function。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(imgs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # tape 用来追踪整个计算图，并记录梯度\n",
    "        preds = model(imgs, training=True)\n",
    "        loss = loss_object(labels, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, preds)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def val_step(imgs, labels):\n",
    "    # 验证的时候，我们不需要进行梯度更新，\n",
    "    # 也就不需要使用tape\n",
    "    preds = model(imgs, training=True)\n",
    "    loss = loss_object(labels, preds)\n",
    "\n",
    "    val_loss(loss)\n",
    "    val_accuracy(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # 模型训练的过程中手动追踪一下模型的训练速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为模型整个训练过程一般是一个循环往复的过程，所以经常性的保存重启模型训练中间过程是有必要的，这里使用 checkpoint 来保存模型中间训练结果，TF 整个系列对 checkpoint 的处理都很方便，这个目前是其他框架有欠缺的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(\".\")\n",
    "# 检查 checkpoint 是否存在\n",
    "if ckpt:\n",
    "    # 如果存在，则加载 checkpoint\n",
    "    model.load_weights(ckpt.model_checkpoint_path)\n",
    "    # 这里是一个比较生硬的方式，其实还可以观察之前训练的过程，\n",
    "    # 手动选择准确率最高的某次 checkpoint 进行加载。\n",
    "    print(\"model lodaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 0 Loss 7.013031005859375, Acc 1.0654706954956055, Val Loss 8.230669975280762, Val Acc 1.3314785957336426\n",
      "Speed train 143.29322678521348imgs/s val 388.28456133362556imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 1 Loss 6.983994960784912, Acc 1.191156268119812, Val Loss 7.239212989807129, Val Acc 1.58982515335083\n",
      "Speed train 145.07717649867584imgs/s val 424.40105396584045imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 2 Loss 6.847441673278809, Acc 1.1654479503631592, Val Loss 6.265858173370361, Val Acc 1.4904611110687256\n",
      "Speed train 145.08648051146173imgs/s val 424.310391109837imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 3 Loss 6.723228454589844, Acc 1.4739488363265991, Val Loss 6.485783576965332, Val Acc 1.073132038116455\n",
      "Speed train 145.78464470680797imgs/s val 427.57270301102767imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 4 Loss 6.531581401824951, Acc 1.3511197566986084, Val Loss 6.291840553283691, Val Acc 1.6494436264038086\n",
      "Speed train 145.263407890806imgs/s val 423.6940316937352imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 5 Loss 6.265165328979492, Acc 2.433729410171509, Val Loss 5.934545040130615, Val Acc 3.17965030670166\n",
      "Speed train 145.2653142213474imgs/s val 420.34738715680373imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 6 Loss 5.966245651245117, Acc 3.770566701889038, Val Loss 5.527194023132324, Val Acc 5.683624744415283\n",
      "Speed train 145.0161027540193imgs/s val 424.09134252558954imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 7 Loss 5.561354160308838, Acc 6.332838535308838, Val Loss 5.119418144226074, Val Acc 9.022257804870605\n",
      "Speed train 145.09997032408435imgs/s val 424.3591220591111imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 8 Loss 5.282253265380859, Acc 8.166705131530762, Val Loss 5.140720367431641, Val Acc 13.354531288146973\n",
      "Speed train 145.21202063938398imgs/s val 420.08636753436036imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 9 Loss 4.686913967132568, Acc 13.694011688232422, Val Loss 4.2854790687561035, Val Acc 18.839427947998047\n",
      "Speed train 144.99150722608616imgs/s val 424.073354309814imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 10 Loss 3.97137713432312, Acc 22.30347442626953, Val Loss 3.4911062717437744, Val Acc 30.723369598388672\n",
      "Speed train 145.1961036067964imgs/s val 423.9780873766499imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 11 Loss 3.196559190750122, Acc 32.66682052612305, Val Loss 2.562021493911743, Val Acc 43.7996826171875\n",
      "Speed train 145.22155624688412imgs/s val 424.14286151519275imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 12 Loss 2.2733497619628906, Acc 45.92093276977539, Val Loss 1.858089566230774, Val Acc 54.789344787597656\n",
      "Speed train 145.13222175598867imgs/s val 427.6923590450844imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 13 Loss 1.6730773448944092, Acc 57.441158294677734, Val Loss 1.3999959230422974, Val Acc 65.12321472167969\n",
      "Speed train 144.8042699643236imgs/s val 416.9634546134006imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 14 Loss 1.2960368394851685, Acc 66.51336669921875, Val Loss 1.140751838684082, Val Acc 70.70747375488281\n",
      "Speed train 145.27358222470602imgs/s val 420.6366541826683imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 15 Loss 1.0543603897094727, Acc 72.64054107666016, Val Loss 1.0251513719558716, Val Acc 74.16534423828125\n",
      "Speed train 145.12764598944767imgs/s val 420.1083757724832imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 16 Loss 0.8770918846130371, Acc 76.98812103271484, Val Loss 0.8745789527893066, Val Acc 77.98092651367188\n",
      "Speed train 144.70931740081332imgs/s val 423.6677595728454imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 17 Loss 0.7574437856674194, Acc 79.91316223144531, Val Loss 0.795542299747467, Val Acc 79.63036346435547\n",
      "Speed train 145.2592458976854imgs/s val 420.54529633588635imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 18 Loss 0.6434058547019958, Acc 82.5125732421875, Val Loss 0.775401771068573, Val Acc 80.78298950195312\n",
      "Speed train 145.2523079045075imgs/s val 427.3079909510649imgs/s\n",
      "Found 35008 images belonging to 100 classes.\n",
      "Found 5000 images belonging to 100 classes.\n",
      "Epoch 19 Loss 0.5517648458480835, Acc 84.81775665283203, Val Loss 0.696952223777771, Val Acc 83.0882339477539\n",
      "Speed train 144.66171171584602imgs/s val 427.60425243186984imgs/s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    # 验证数据都是针对整个 epoch 的，\n",
    "    # 所以每个 epoch 之间要对这些数据初始化一下。\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "    total_trained = 0\n",
    "    total_valed = 0\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for imgs, labels in img_gen_train.flow_from_directory(\n",
    "        \"worddata/train/\",\n",
    "        target_size=(128, 128),\n",
    "        color_mode=\"grayscale\",\n",
    "        classes=classes,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "    ):\n",
    "        # 之前生成的 img_train 是个 generator，而且它不会自动重启和结束，\n",
    "        # 一旦启动，只要不手动结束，它会一直无限循环输出数据，因此这里手动处\n",
    "        # 理一下数据的生成，并做一个计数。\n",
    "\n",
    "        train_step(imgs, labels)\n",
    "        total_trained += imgs.shape[0]\n",
    "        if total_trained > 35000:\n",
    "            break\n",
    "    period = time.time() - start\n",
    "    train_samples_per_second = total_trained / period\n",
    "\n",
    "    start = time.time()\n",
    "    for imgs, labels in img_gen_val.flow_from_directory(\n",
    "        \"worddata/validation/\",\n",
    "        target_size=(128, 128),\n",
    "        color_mode=\"grayscale\",\n",
    "        classes=classes,\n",
    "        batch_size=32,\n",
    "    ):\n",
    "        val_step(imgs, labels)\n",
    "        total_valed += imgs.shape[0]\n",
    "        if total_valed > 5000:\n",
    "            break\n",
    "    period = time.time() - start\n",
    "    val_samples_per_second = total_valed / period\n",
    "\n",
    "    print(\n",
    "        \"Epoch {} Loss {}, Acc {}, Val Loss {}, Val Acc {}\".format(\n",
    "            epoch,\n",
    "            train_loss.result(),\n",
    "            train_accuracy.result() * 100,\n",
    "            val_loss.result(),\n",
    "            val_accuracy.result() * 100,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Speed train {}imgs/s val {}imgs/s\".format(\n",
    "            train_samples_per_second, val_samples_per_second\n",
    "        )\n",
    "    )\n",
    "    model.save_weights(\"model-{:04d}.ckpt\".format(epoch))\n",
    "    # 每个 epoch 保存一下模型，需要注意每次\n",
    "    # 保存要用一个不同的名字，不然会导致覆盖，\n",
    "    # 同时还要关注一下磁盘空间占用，防止太多\n",
    "    # chekcpoint 占满磁盘空间导致错误。\n",
    "    # 注意这个 API 调用每次都会生成数个文件，\n",
    "    # 其中 checkpoint 文件用来记录每次的文\n",
    "    # 件路径，其他文件则存储模型数据和索引信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一些技巧\n",
    "\n",
    "因为这里定义的模型比较大，同时训练的数据也比较多，每个 epoch 用时较长，因此，如果代码有 bug 的话，经过一次 epoch 再去 debug 效率比较低。\n",
    "\n",
    "这种情况下，我们使用的数据生成过程又是自己手动指定数据数量的，因此可以尝试缩减模型规模，定义小一些的数据集来快速验证代码。在这个例子里，我们可以通过注释模型中的卷积和全连接层的代码来缩减模型尺寸，通过修改训练循环里面的数据数量来缩减数据数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
